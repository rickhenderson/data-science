citation()
demo()
colors
demo(package = grDevices)
help demos
ls
help
help.start()
a = 3
a=3;
b+a
b=a
a=7
a_b
a+b
a-b
c = a * b
cls
clear
ls
x <- rnorm(50)
y <- rnorm(x)
plot(x,y)
help rnorm
help.rnorm
help.rnorm()
help rnorm()
rnorm.help
ls()
rm(x,y)
x <-1:20
w<-1+sqrt(x)/2
dummy<-data.frame(x=x, y=x+rnorm(x)*w)
View(dummy)
View(dummy)
dummy
view(dummy)
fm <- lm(y~x, data=dummy)
summary(fm)
temp = x > 13
temp
q()
setwd("I:/Data Science/Getting and Cleaning Data")
install.packages("httr")
library(httr)
url <- "http://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en"
# Use the HTTP GET request to retrieve more than just the HTML code
html2 = GET(url)
# Extract the web page content out of the GET request
content2 = content(html2, as="text")
# Parse the HTML content
parsedHtml = htmlParse(content2, asText=TRUE)
# Extract the title
pageTitle <- xpathSApply(parsedHtml, "//title", xmlValue)
library(httr)
parsedHtml = htmlParse(content2, asText=TRUE)
library(XML)
install.packages("XML")
library(httr)
url <- "http://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en"
# Use the HTTP GET request to retrieve more than just the HTML code
html2 = GET(url)
# Extract the web page content out of the GET request
content2 = content(html2, as="text")
# Parse the HTML content
parsedHtml = htmlParse(content2, asText=TRUE)
# Extract the title
pageTitle <- xpathSApply(parsedHtml, "//title", xmlValue)
library(XML)
library(httr)
url <- "http://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en"
# Use the HTTP GET request to retrieve more than just the HTML code
html2 = GET(url)
# Extract the web page content out of the GET request
content2 = content(html2, as="text")
# Parse the HTML content
parsedHtml = htmlParse(content2, asText=TRUE)
# Extract the title
pageTitle <- xpathSApply(parsedHtml, "//title", xmlValue)
source('I:/Data Science/Getting and Cleaning Data/readingHDF5.R')
install.packages("swirl")
packageVersion("swirl")
library(swirl)
install_from_swirl("Getting and Cleaning Data")
swirl()
mydf <- read.csv(path2csv, stringsAsFactors = FALSE)
dim(mydf)
head(mydf)
bye()
setwd("I:/GitHub/data-science/gettidydata")
# Reading From APIs
# From Getting And Cleaning Data
# Week 2 - Coursera
# Use httr
library(httr)
# Protect these keys from becoming public.
myapp = oauth_app("twitter",
key="efYMRwir780488TltaIuov5h4",
secret=" iwJpCbi6UruNDJyJ7SwoWABNCEmTjeKyjhhwahpTbzRQtU3n0S")
sig = sign_oauth1.0(myapp,
token = "14335985-pnjQ23OjTrXhexyIvtUKMzzszWM3v5b9qHC83hl18",
token_secret = "gpAlUEhoRBLe36DlNUACQMgSzh3ZBmyjoNEAGN5eakKvp")
# Reading From APIs
# From Getting And Cleaning Data
# Week 2 - Coursera
# Use httr
library(httr)
# Protect these keys from becoming public.
myapp = oauth_app("twitter",
key="efYMRwir780488TltaIuov5h4",
secret=" iwJpCbi6UruNDJyJ7SwoWABNCEmTjeKyjhhwahpTbzRQtU3n0S")
sig = sign_oauth1.0(myapp,
token = "14335985-pnjQ23OjTrXhexyIvtUKMzzszWM3v5b9qHC83hl18",
token_secret = "gpAlUEhoRBLe36DlNUACQMgSzh3ZBmyjoNEAGN5eakKvp")
homeTL = GET("https://api.twitter.com/1.1/statuses/home_timeline.json", sig)
# Use content() to extract the requested data
json1 = content(homeTL)
# Use toJSON to convert the R data back into JSON,
# then use fromJSON to turn it into a dataframe.
json2 = jsonlite::fromJSON(toJSON(json1))
json2[1,1:4]
# Note: Visit the Twitter API to see which website to request for other info
# https://dev.twitter.com/docs/api/1.1/overview
# Use httr
library(httr)
# Protect these keys from becoming public.
myapp = oauth_app("twitter",
key="efYMRwir780488TltaIuov5h4",
secret="iwJpCbi6UruNDJyJ7SwoWABNCEmTjeKyjhhwahpTbzRQtU3n0S")
sig = sign_oauth1.0(myapp,
token = "14335985-pnjQ23OjTrXhexyIvtUKMzzszWM3v5b9qHC83hl18",
token_secret = "gpAlUEhoRBLe36DlNUACQMgSzh3ZBmyjoNEAGN5eakKvp")
homeTL = GET("https://api.twitter.com/1.1/statuses/home_timeline.json", sig)
# Use content() to extract the requested data
json1 = content(homeTL)
# Use toJSON to convert the R data back into JSON,
# then use fromJSON to turn it into a dataframe.
json2 = jsonlite::fromJSON(toJSON(json1))
json2[1,1:4]
# Note: Visit the Twitter API to see which website to request for other info
# https://dev.twitter.com/docs/api/1.1/overview
library(jsonlite)
a <- toJson(json1)
a <- toJSON(json1)
fromJSON(a)
b <- fromJSON(a)
b
json2[1,1:4]
b[1,1:4]
source('I:/GitHub/data-science/gettidydata/myTwitterStats_rdh.R')
# Use httr & jsonLite
library(httr)
library(jsonlite)
# Protect these keys from becoming public.
myapp = oauth_app("twitter",
key="efYMRwir780488TltaIuov5h4",
secret="iwJpCbi6UruNDJyJ7SwoWABNCEmTjeKyjhhwahpTbzRQtU3n0S")
sig = sign_oauth1.0(myapp,
token = "14335985-pnjQ23OjTrXhexyIvtUKMzzszWM3v5b9qHC83hl18",
token_secret = "gpAlUEhoRBLe36DlNUACQMgSzh3ZBmyjoNEAGN5eakKvp")
homeTL = GET("https://api.twitter.com/1.1/statuses/home_timeline.json", sig)
# Use content() to extract the requested data
json1 = content(homeTL)
# Use toJSON to convert the R data back into JSON,
# then use fromJSON to turn it into a dataframe.
json2 = fromJSON(toJSON(json1))
json2[1,1:4]
# Note: Visit the Twitter API to see which website to request for other info
# https://dev.twitter.com/docs/api/1.1/overview
source('I:/GitHub/data-science/gettidydata/myTwitterStats_rdh.R')
# Use httr & jsonLite
library(httr)
library(jsonlite)
# Protect these keys from becoming public.
myapp = oauth_app("twitter",
key="efYMRwir780488TltaIuov5h4",
secret="iwJpCbi6UruNDJyJ7SwoWABNCEmTjeKyjhhwahpTbzRQtU3n0S")
sig = sign_oauth1.0(myapp,
token = "14335985-pnjQ23OjTrXhexyIvtUKMzzszWM3v5b9qHC83hl18",
token_secret = "gpAlUEhoRBLe36DlNUACQMgSzh3ZBmyjoNEAGN5eakKvp")
homeTL = GET("https://api.twitter.com/1.1/statuses/home_timeline.json", sig)
# Use content() to extract the requested data
json1 = content(homeTL)
# Use toJSON to convert the R data back into JSON,
# then use fromJSON to turn it into a dataframe.
json2 = fromJSON(toJSON(json1))
message("The most recent tweet is: ", json2[1,4])
# Note: Visit the Twitter API to see which website to request for other info
# https://dev.twitter.com/docs/api/1.1/overview
source('I:/GitHub/data-science/gettidydata/myTwitterStats_rdh.R')
source('I:/GitHub/data-science/gettidydata/myTwitterStats_rdh.R')
